{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.creativecommons.org/l/by/4.0/88x31.png)\n",
    "# Rodando Spider na nuvem\n",
    "\n",
    "![](https://media.giphy.com/media/xUNd9AjPuYZOGB4V4Q/giphy.gif)\n",
    "\n",
    "Agora que já sabemos bastante sobre Raspagem de dados, vamos automatizar mais ainda o processo e vamos rodar a Spider na nuvem.\n",
    "\n",
    "* Para esse tutorial vamos precisar instalar shub.\n",
    "    `pip install shub`\n",
    "    \n",
    "* Tambem vamos precisar criar uma conta no [site](https://scrapinghub.com) onde iremos hospedar nossa Spider.\n",
    "\n",
    "## Criando o nosso projeto\n",
    "\n",
    "Vamos criar um projeto onde terão todos os dados necessários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy startproject Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos editar nossa spider, acesse a pasta `/Cloud/Spiders`, acesse o arquivo `__init__.py`, essa será nossa spider, eu estarei usando o código do tutorial [Navegando entre paginas](https://github.com/DwarfThief/Raspagem-de-dados-para-iniciantes/blob/master/Tutoriais/Navegando%20entre%20paginas.ipynb). Após alterar o arquivo e salvar, é hora de testar se a Spider esta funcionando como o planejado.\n",
    "\n",
    "Dessa vez será um pouco diferente, vamos usar o comando `crawl` e passando como parâmetro o nome dado para a Spider que criamos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando o app\n",
    "\n",
    "Agora que já testamos nossa Spider e o projeto, ta na hora de configurar o app para nossa Spider.\n",
    "\n",
    "### 1. Essa é a primeira página que veremos, crie um novo projeto:\n",
    "\n",
    "![](./resources/rodando_spider_na_nuvem/01.png)\n",
    "\n",
    "### 2. Teremos que importar nossa Spider para a nuvem.\n",
    "* Vamos ter que realizar o login no `shub login`, será solicitado a API Key, cobri o meu por razões de segurança.\n",
    "* Agora vamos dar o `shub deploy <numero-do-projeto>` para enviar nossa spider para o servidor (o número do projeto tambem se encontra na página).\n",
    "\n",
    "![](./resources/rodando_spider_na_nuvem/02.png)\n",
    "\n",
    "### 3. Vamos acessar a lista das nossas Spiders, é aqui que ficam as Spiders que importamos.\n",
    "\n",
    "![](./resources/rodando_spider_na_nuvem/03.png)\n",
    "\n",
    "### 4. Ao clicar na Spider teremos acesso as informações dela.\n",
    "\n",
    "![](./resources/rodando_spider_na_nuvem/04.png)\n",
    "\n",
    "### 5. Vamos rodar a Spider clicando em `Run`.\n",
    "* Aqui podemos categorizar e descrever a atividade realizada pela Spider.\n",
    "\n",
    "![](./resources/rodando_spider_na_nuvem/05.png)\n",
    "\n",
    "### 6. Esse é o painel onde podemos ver todas as Spiders em ação, no nosso caso, apenas uma.\n",
    "\n",
    "![](./resources/rodando_spider_na_nuvem/06.png)\n",
    "\n",
    "### 7. Ao finalizar, poder ter acesso ao log de eventos da Spider, assim como a quantidade de resquests e claro... aos dados que ela foi capaz de minerar.\n",
    "\n",
    "![](./resources/rodando_spider_na_nuvem/07.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
